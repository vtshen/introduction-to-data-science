{
 "metadata": {
  "name": "",
  "signature": "sha256:69d9de666df5b601045a4d60f2799a642e1a4afa1f6f7896a77c28ac30da87c4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile /data/airline/Wei_Chen_mapper.py\n",
      "#!/usr/bin/python3\n",
      "\n",
      "import sys, os\n",
      "\n",
      "sep = '\\t'\n",
      "\n",
      "# We open STDIN and STDOUT\n",
      "with sys.stdin as fin:\n",
      "    with sys.stdout as fout:\n",
      "    \n",
      "        # For every line in STDIN\n",
      "        for line in fin:\n",
      "        \n",
      "            # Strip off leading and trailing whitespace\n",
      "            line = line.strip()\n",
      "            \n",
      "            # We split the line into word tokens. Use whitespace to split.\n",
      "            # Note we don't deal with punctuation.\n",
      "            \n",
      "            word = line.split(\",\")[16] # Origin is the 17th column\n",
      "\n",
      "            fout.write(\"{0}{1}1\\n\".format(word, sep))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting /data/airline/Wei_Chen_mapper.py\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile /data/airline/Wei_Chen_reducer.py\n",
      "#!/usr/bin/python3\n",
      "\n",
      "import sys\n",
      "\n",
      "# We explicitly define the word/count separator token.\n",
      "sep = '\\t'\n",
      "\n",
      "# We open STDIN and STDOUT\n",
      "with sys.stdin as fin:\n",
      "    with sys.stdout as fout:\n",
      "    \n",
      "        # Keep track of current word and count\n",
      "        cword = None\n",
      "        ccount = 0\n",
      "        word = None\n",
      "   \n",
      "        # For every line in STDIN\n",
      "        for line in fin:\n",
      "        \n",
      "            # Strip off leading and trailing whitespace\n",
      "            # Note by construction, we should have no leading white space\n",
      "            line = line.strip()\n",
      "            \n",
      "            # We split the line into a word and count, based on predefined\n",
      "            # separator token.\n",
      "            # Note we haven't dealt with punctuation.\n",
      "            \n",
      "            word, scount = line.split('\\t', 1)\n",
      "            \n",
      "            # We wil assume count is always an integer value\n",
      "            \n",
      "            count = int(scount)\n",
      "            \n",
      "            # word is either repeated or new\n",
      "            \n",
      "            if cword == word:\n",
      "                ccount += count\n",
      "            else:\n",
      "                # We have to handle first word explicitly\n",
      "                if cword != None:\n",
      "                    fout.write(\"{0:s}{1:s}{2:d}\\n\".format(cword, sep, ccount))\n",
      "                \n",
      "                # New word, so reset variables\n",
      "                cword = word\n",
      "                ccount = count\n",
      "        else:\n",
      "            # Output final word count\n",
      "            if cword == word:\n",
      "                fout.write(\"{0:s}{1:s}{2:d}\\n\".format(word, sep, ccount))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting /data/airline/Wei_Chen_reducer.py\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "export PYTHONIOENCODING=latin-1\n",
      "TEMP_PATH=\"/data/airline\";\n",
      "$TEMP_PATH/Wei_Chen_mapper.py < $TEMP_PATH/2001.csv | sort -n -k 1 | $TEMP_PATH/Wei_Chen_reducer.py | sort -n -k 2 | tail -10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BOS\t133013\n",
        "LAS\t136107\n",
        "MSP\t142507\n",
        "DTW\t148767\n",
        "STL\t162187\n",
        "PHX\t184323\n",
        "LAX\t224984\n",
        "ATL\t251671\n",
        "DFW\t312036\n",
        "ORD\t341284\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}